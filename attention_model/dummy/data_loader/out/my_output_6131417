loaded train data loader
loaded valid
started
(100, 60, 32, 0.0001)
{'hidden_dim': 100, 'input_dim': 300} {'hidden_dim': 60, 'input_dim': 74} {'hidden_dim': 32, 'input_dim': 47} 128
gpu found
{'a': 60, 'lr': 0.0001, 'l': 100, 'f': 32}
Traceback (most recent call last):
  File "/home/mhasan8/ets/deep_learning/attention_model/train_attention_mosi_data_loader.py", line 238, in <module>
    train_mosi_sentiments(mosi_model,params_config)
  File "/home/mhasan8/ets/deep_learning/attention_model/train_attention_mosi_data_loader.py", line 190, in train_mosi_sentiments
    train_loss=train_epoch(mosi_model, opt, criterion)
  File "/home/mhasan8/ets/deep_learning/attention_model/train_attention_mosi_data_loader.py", line 103, in train_epoch
    y_hat=mosi_model.forward(x)
  File "/gpfs/fs1/home/mhasan8/ets/deep_learning/attention_model/attention_model.py", line 179, in forward
    z=self.mab_net.forward(h_i,z_init)
  File "/gpfs/fs1/home/mhasan8/ets/deep_learning/attention_model/attention_model.py", line 121, in forward
    w_t=self.s(self.attention_weigths[i](z))
  File "/home/mhasan8/.local/lib/python2.7/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/mhasan8/.local/lib/python2.7/site-packages/torch/nn/modules/linear.py", line 55, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/mhasan8/.local/lib/python2.7/site-packages/torch/nn/functional.py", line 1024, in linear
    return torch.addmm(bias, input, weight.t())
RuntimeError: Expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument #4 'mat1'
